{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iqra-01/Google_AI_studio_Genai/blob/main/templates/ML%20confusion%20matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kWIuwKG2_oWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d555e7-9439-4318-81ef-eb7d781d6e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"I am a student learning ML. I have a trained a model to predict whether an image is a cat, dog, or squirrel. These are the predictions I&#39;ve gotten from my model, and the ground truth from my labels. Here, 0 corresponds to cat, 1 to dog, and 2 to squirrel.\\\\n\\\\npredictions = [0, 0, 1, 1, 0, 0, 2, 2, 1, 0]\\\\nground_truth = [0, 1, 1, 1, 1, 0, 2, 2, 2, 2]\\\\n\\\\nI would like to make a confusion matrix using sklearn. I would also like to output metrics like precision, recall, and accuracy. And I would like to visualize the confusion matrix by plotting it. The plot should show the class names instead of the numeric labels.\\\\n\\\\nCan you generate code to do this for me in Python?\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"model\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"Here's a Python solution using scikit-learn (sklearn) to create a confusion matrix, calculate precision, recall, and accuracy, and visualize the confusion matrix with class names.\\\\n\\\\n```python\\\\nimport numpy as np\\\\nimport matplotlib.pyplot as plt\\\\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\\\\nimport seaborn as sns\\\\n\\\\npredictions = np.array([0, 0, 1, 1, 0, 0, 2, 2, 1, 0])\\\\nground_truth = np.array([0, 1, 1, 1, 1, 0, 2, 2, 2, 2])\\\\nclass_names = [\\\\\\\"cat\\\\\\\", \\\\\\\"dog\\\\\\\", \\\\\\\"squirrel\\\\\\\"]\\\\n\\\\n\\\\n# Calculate the confusion matrix\\\\ncm = confusion_matrix(ground_truth, predictions)\\\\n\\\\n# Calculate accuracy, precision and recall\\\\naccuracy = accuracy_score(ground_truth, predictions)\\\\nreport = classification_report(ground_truth, predictions, target_names=class_names)\\\\n\\\\n\\\\n# Visualize the confusion matrix\\\\nplt.figure(figsize=(8, 6))\\\\nsns.heatmap(cm, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\", \\\\n            xticklabels=class_names, yticklabels=class_names)\\\\nplt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\nplt.ylabel(\\\\\\\"True\\\\\\\")\\\\nplt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\nplt.show()\\\\n\\\\n# Print the classification report \\\\nprint(\\\\\\\"Classification Report:\\\\\\\\n\\\\\\\", report)\\\\nprint(\\\\\\\"Accuracy:\\\\\\\", accuracy)\\\\n\\\\n```\\\\n\\\\nThis code first calculates the confusion matrix using `confusion_matrix`.  Then it computes  the accuracy using `accuracy_score` and a classification report (including precision and recall) using `classification_report`. Finally, it uses `seaborn` (make sure you have `seaborn` installed: `pip install seaborn`) to create a heatmap visualization of the confusion matrix with the class names clearly labeled.  The classification report and accuracy are then printed to the console. Remember to install the necessary libraries (`scikit-learn`, `matplotlib`, `seaborn`) if you haven't already.\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# import necessary modules.\n",
        "import base64\n",
        "import copy\n",
        "import json\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "try:\n",
        "    # The SDK will automatically read it from the GOOGLE_API_KEY environment variable.\n",
        "    # In Colab get the key from Colab-secrets (\"🔑\" in the left panel).\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Parse the arguments\n",
        "\n",
        "model = 'gemini-1.5-flash' # @param {isTemplate: true}\n",
        "contents_b64 = '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' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MiwidG9wX3AiOjAuOTUsInRvcF9rIjo0MCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "# Convert and upload the files\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data, index):\n",
        "    \"\"\"Upload files to the Files API.\n",
        "\n",
        "    For each file, Google AI Studio either sent:\n",
        "    - a Google Drive ID,\n",
        "    - a URL,\n",
        "    - a file path, or\n",
        "    - The raw bytes (`inline_data`).\n",
        "\n",
        "    The API only understands `inline_data` or it's Files API.\n",
        "    This code, uploads files to the files API where the API can access them.\n",
        "    \"\"\"\n",
        "\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        path = tempfiles / str(index)\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"📁 Files\" in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "\n",
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "index = 0\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data, index)\n",
        "            index += 1\n",
        "\n",
        "import json\n",
        "print(json.dumps(contents, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385b7ace-cfc7-4901-c38c-5589ea8ffffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model did not return any candidates. Please check your prompt and configuration.\n",
            "Response details: response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 713,\n",
            "        \"total_token_count\": 713\n",
            "      }\n",
            "    }),\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=stream,\n",
        ")\n",
        "\n",
        "if response.candidates:\n",
        "    display(Markdown(response.text))\n",
        "else:\n",
        "    print(\"The model did not return any candidates. Please check your prompt and configuration.\")\n",
        "    # Optionally, you can print more details about the response:\n",
        "    print(f\"Response details: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9d345e9868"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />Docs on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />More notebooks in the Cookbook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91AeeGO1ncU"
      },
      "source": [
        "## [optional] Show the conversation\n",
        "\n",
        "This section displays the conversation received from Google AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "yoL3p3KPylFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1514d54-1205-47ee-b224-af89b7e0cbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Role: user \n",
            "\n",
            "I am a student learning ML. I have a trained a model to predict whether an image is a cat, dog, or squirrel. These are the predictions I&#39;ve gotten from my model, and the ground truth from my labels. Here, 0 corresponds to cat, 1 to dog, and 2 to squirrel.\\n\\npredictions = [0, 0, 1, 1, 0, 0, 2, 2, 1, 0]\\nground_truth = [0, 1, 1, 1, 1, 0, 2, 2, 2, 2]\\n\\nI would like to make a confusion matrix using sklearn. I would also like to output metrics like precision, recall, and accuracy. And I would like to visualize the confusion matrix by plotting it. The plot should show the class names instead of the numeric labels.\\n\\nCan you generate code to do this for me in Python? \n",
            "\n",
            "-------------------------------------------------------------------------------- \n",
            "\n",
            "Role: model \n",
            "\n",
            "Here's a Python solution using scikit-learn (sklearn) to create a confusion matrix, calculate precision, recall, and accuracy, and visualize the confusion matrix with class names.\\n\\n```python\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\\nimport seaborn as sns\\n\\npredictions = np.array([0, 0, 1, 1, 0, 0, 2, 2, 1, 0])\\nground_truth = np.array([0, 1, 1, 1, 1, 0, 2, 2, 2, 2])\\nclass_names = [\\\"cat\\\", \\\"dog\\\", \\\"squirrel\\\"]\\n\\n\\n# Calculate the confusion matrix\\ncm = confusion_matrix(ground_truth, predictions)\\n\\n# Calculate accuracy, precision and recall\\naccuracy = accuracy_score(ground_truth, predictions)\\nreport = classification_report(ground_truth, predictions, target_names=class_names)\\n\\n\\n# Visualize the confusion matrix\\nplt.figure(figsize=(8, 6))\\nsns.heatmap(cm, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", \\n            xticklabels=class_names, yticklabels=class_names)\\nplt.xlabel(\\\"Predicted\\\")\\nplt.ylabel(\\\"True\\\")\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\\n\\n# Print the classification report \\nprint(\\\"Classification Report:\\\\n\\\", report)\\nprint(\\\"Accuracy:\\\", accuracy)\\n\\n```\\n\\nThis code first calculates the confusion matrix using `confusion_matrix`.  Then it computes  the accuracy using `accuracy_score` and a classification report (including precision and recall) using `classification_report`. Finally, it uses `seaborn` (make sure you have `seaborn` installed: `pip install seaborn`) to create a heatmap visualization of the confusion matrix with the class names clearly labeled.  The classification report and accuracy are then printed to the console. Remember to install the necessary libraries (`scikit-learn`, `matplotlib`, `seaborn`) if you haven't already.\\n \n",
            "\n",
            "-------------------------------------------------------------------------------- \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Show the conversation, in colab.\n",
        "import mimetypes\n",
        "\n",
        "def show_file(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "\n",
        "    if drive_id := file_data.get(\"drive_id\", None):\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        name = path\n",
        "        # data = path.read_bytes()\n",
        "        kwargs = {\"filename\": path}\n",
        "    elif url := file_data.get(\"url\", None):\n",
        "        name = url\n",
        "        kwargs = {\"url\": url}\n",
        "        # response = requests.get(url)\n",
        "        # data = response.content\n",
        "    elif data := file_data.get(\"inline_data\", None):\n",
        "        name = None\n",
        "        kwargs = {\"data\": data}\n",
        "    elif name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files to \"\n",
        "                'Colab using the file manager (\"📁 Files\"in the left toolbar)'\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "        print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "        return\n",
        "\n",
        "    format = mimetypes.guess_extension(mime_type).strip(\".\")\n",
        "    if mime_type.startswith(\"image/\"):\n",
        "        image = IPython.display.Image(**kwargs, width=256)\n",
        "        IPython.display.display(image)\n",
        "        print()\n",
        "        return\n",
        "\n",
        "    if mime_type.startswith(\"audio/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Audio(**kwargs)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    if mime_type.startswith(\"video/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Video(**kwargs, mimetype=mime_type)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "\n",
        "\n",
        "for content in gais_contents:\n",
        "    if role := content.get(\"role\", None):\n",
        "        print(\"Role:\", role, \"\\n\")\n",
        "\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if text := part.get(\"text\", None):\n",
        "            print(text, \"\\n\")\n",
        "\n",
        "        elif file_data := part.get(\"file_data\", None):\n",
        "            show_file(file_data)\n",
        "\n",
        "    print(\"-\" * 80, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}